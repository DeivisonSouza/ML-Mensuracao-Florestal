---
title: "Aprendizado de M√°quina <BR> na Mensura√ß√£o Florestal:"
subtitle: "T√©cnicas, Modelagem e Aplica√ß√£o Web  <BR> <BR> <BR> <BR>"
#subtitle: "Potencial para modelagem de vari√°veis florestais"
author: "<BR> Prof. Dr. Deivison Venicio Souza"
institute: |
  | Universidade Federal do Par√° (UFPA) <BR> <BR> 
date: | 
  .center[`r format(Sys.Date(),"%d/%B/%Y")` <BR> 
   Altamira, Par√° <BR> ]
encoding: "UTF-8"
#output: revealjs::revealjs_presentation
#output: rmdshower::shower_presentation
header-includes: 
   - \usepackage{multirow}
   - \usepackage[brazil]{babel}
   - \usepackage{tikz}
   - \usepackage[hidelinks,pdfencoding=auto]{hyperref}
   - \usepackage{smartdiagram}
output:
  xaringan::moon_reader:
    includes:
      after_body: css/sydney.css
    css: [default, metropolis] #xaringan-themer.css 
    lib_dir: libs
    nature:
      #autoplay: 30000
      #countdown: 60000
      #titleSlideClass: [top, left, inverse]
      highlightStyle: idea #monokai
      highlightLines: true
      highlightLanguage: r
      countIncrementalSlides: false
      ratio: "16:9"
    seal: true
---

name: toc

```{r setup, include=FALSE, cache=FALSE, eval=TRUE}
library(tidyverse)
library(rpart)                            
library(rpart.plot)
library(kableExtra)
library(plotly)

options(htmltools.dir.version = FALSE,
        servr.daemon = TRUE)

knitr::opts_chunk$set(
  fig.showtext = TRUE,
  fig.align = "center", 
  cache = TRUE,
  error = FALSE,
  message = FALSE, 
  warning = FALSE, 
  collapse = TRUE ,
  dpi = 600,
  dev.args=list(bg='transparent')
)

```

```{r xaringanExtra, echo=FALSE, eval=TRUE}
library(xaringanExtra)
# use_logo(
#   image_url = "fig/ufpa.png",
#   position = css_position(top = ".8em", right = "1em"),
#   width = "140px",
#   height = "140px"
# )
# 
use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)

# use_tachyons()
use_panelset()
# use_clipboard()
#style_panelset(panel_tab_color_active = "red")
```

```{r xaringanthemer, warning=FALSE, include=FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#43418A",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```

```{r, load_refs, include=FALSE, cache=FALSE}
library(RefManageR)
BibOptions(check.entries = FALSE,
           style = "markdown",
           bib.style = "authoryear",
           cite.style = "authoryear",
           first.inits = TRUE,
           style = "html",
           hyperlink = FALSE,
           dashed = FALSE)
(myBib <- ReadBib("./bib/ref.bib", check = FALSE))
```

# üëã Ol√°!

## <bdi style="color:magenta;">1. Deivison Souza </bdi>

.pull-left[
* <bdi style="font-weight:bold">Gradua√ß√£o (Titula√ß√£o: ano 2008)</bdi>
    + Universidade Federal Rural da Amaz√¥nia (UFRA); e
    + T√≠tulo: Bacharel em Engenharia Florestal.

* <bdi style="font-weight:bold">Mestrado (Titula√ß√£o: ano 2011)</bdi>
    + Universidade Federal Rural da Amaz√¥nia (UFRA);
    + Programa de P√≥s-gradua√ß√£o em Ci√™ncias Florestais (PPGCF); e
    + √Årea de Concentra√ß√£o: Manejo de ecossistemas florestais.
]

.pull-right[
* <bdi style="font-weight:bold">Doutorado (Titula√ß√£o: ano 2020)</bdi>
    + Universidade Federal do Paran√° (UFPR);
    + Programa de P√≥s-gradua√ß√£o em Engenharia Florestal (PPGEF); e
    + √Årea de Concentra√ß√£o: Manejo Florestal.
    
* <bdi style="font-weight:bold">Especializa√ß√£o (Defesa: ano 2019)</bdi>
    + Universidade Federal do Paran√° (UFPR);
    + √Årea: Big Data e Data Science
]

<!-- Slide 2 -->
---
background-image: url(fig/white.jpg)
background-size: cover
# Conte√∫do

.pull-top[
**Parte 1 - Conceitos e fundamenta√ß√£o te√≥rica**

[1 - Qual √© o motivo de fazer an√°lise de regress√£o?](#AR)

[2 - Culturas na modelagem estat√≠stica](#CultME)

[3 - Aprendizado de M√°quina](#AM)

&nbsp;&nbsp;[3.1 - Tipos de Aprendizagem](#TA)

&nbsp;&nbsp;[3.2 - Algoritmos de Aprendizado Supersivionado](#AAS)

&nbsp;&nbsp;&nbsp;&nbsp;[3.2.1 - Regression Tree](#RT)

&nbsp;&nbsp;&nbsp;&nbsp;[3.2.2 - Bagging](#bag)

&nbsp;&nbsp;&nbsp;&nbsp;[3.2.3 - Random Forest](#rf)

&nbsp;&nbsp;&nbsp;&nbsp;[3.2.4 - Outros (M5', ...)](#out)

&nbsp;&nbsp;[3.3 - M√©todos de Reamostragem](#mr)

&nbsp;&nbsp;[3.4 - Medidas de Desempenho](#md)

]

<!-- Slide 2 -->
---
background-image: url(fig/white.jpg)
background-size: cover
# Conte√∫do

.pull-top[

**Parte 2 - Aprendizado de M√°quina com Linguagem R**

[1 - Bibliotecas no Cran Task View](#bctv)

[2 - Pacote CARET](#caret)

[3 - Fluxograma: aprendizado de MAM usando CARET](#fluxo)

[4 - Modelagem no R: uma r√°pida intui√ß√£o](#exR)

[5 - Aplica√ß√£o Web com MAM: demonstra√ß√£o.](#shiny)


**Parte 3 - Aplica√ß√µes nas Ci√™ncias Florestais**

[1 - Aplica√ß√µes nas ci√™ncias florestais](#aplicacoes)

[2 - Considera√ß√µes finais](#cf)

]

<br> <br>

.left[.footnote[Imagem de <a href="https://pixabay.com/pt/users/pen_ash-5526837/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5358904">pen_ash</a> por <a href="https://pixabay.com/pt/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5358904">Pixabay</a>]]


<!-- Slide XX -->
---
name: AR
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Parte 1** <br> .green[Conceitos e fundamenta√ß√£o te√≥rica]]

<!-- Slide XX -->
---
name: AR
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Qual √© o motivo de fazer <br> an√°lise de regress√£o?**]


<!--Slide 3 -->
---
# Uma an√°lise de regress√£o...

.pull-left-2[
.blockquote[
.center[**Motivos pr√°ticos**]

- **Determina√ß√£o**: Vari√°veis dif√≠ceis de determinar em campo;
  - ex.: volume, biomassa, altura, etc.
- **Alto custo**: Almeja-se diminuir custos!
- **Larga escala**: Imagine fazer isso em larga escala! √â impratic√°vel!
- **Alternativa**: Usar m√©todos indiretos.
]
]

.pull-right-1[
```{r, echo=FALSE, out.width='50%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/imgCub.jpg')
```
<br>
.center[**Nas florestas inequi√¢neas as dificuldades octuplicam!**]
]

**Regress√£o Linear**: M√©todo mais tradicional!

$v = \beta_0 + \beta_{1}(d^2h) + \epsilon_i$ $\Rightarrow$ **Spurr (1952)**

$ln (v) = ln\beta_0 + \beta_{1}ln(d) + \beta_{2}ln(h) + \epsilon_i$ $\Rightarrow$ **Schumacher-Hall (1933)**

<!--Slide 4 -->
---
# Uma an√°lise de regress√£o...

.blockquote[
.center[**Motivos estat√≠sticos** `r Citep(myBib, "izbicki_mendonca2020")`]

- **Inferencial**: Tirar conclus√µes sobre a popula√ß√£o.
  - Interpretar par√¢metros;
  - Estimar os intervalos de confian√ßa (IC) dos par√¢metros; e
  - Testes de hip√≥teses (normalidade, homocedasticidade dos res√≠duos, etc.) $\Rightarrow$ .content-box-red[Suposi√ß√µes da RL]

*Por exemplo:* Admitindo o modelo $v = \beta_0 + \beta_1d + \epsilon_i$ (**Berkhout**)

Qual a rela√ß√£o entre $v$ e o $d$?

Qual efeito no volume para uma unidade de mudan√ßa no di√¢metro da √°rvore?

- **Preditivista**: 
  - Estimar uma fun√ß√£o de regress√£o $f(x)$ com bom poder preditivo! .content-box-red[O foco √© na predi√ß√£o!]
]

--

.content-box-blue[
.center[**Portanto, para um determinado problema o foco pode ser claramente inferencial ou preditivo, e para outros pode ser a mistura de ambos** `r Citep(myBib, "izbicki_mendonca2020")`.]
]

<!-- Slide XX -->
---
name: CultME
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Culturas na modelagem <br> estat√≠stica**]

<!--Slide 5 -->
---
# As duas culturas...`r Citep(myBib, "breiman2001statistical")`

.pull-left-2[
.blockquote[

- **Data modeling culture**
  - *Objetivo principal*: .content-box-red[infer√™ncia] (interpretabilidade)
  - *Predomina*: comunidade estat√≠stica
  - *Popula√ß√£o estimada*: 98% de todos os estat√≠sticos
  - *Forma funcional*: suposi√ß√£o da forma funcional $f(x)$ 
  - *Par√¢metros*: s√£o estimados a partir dos dados
]

.blockquote[
- **Algorithmic modeling culture**
  - *Objetivo principal*: .content-box-red[predi√ß√£o] (poder preditivo!)
  - *Predomina*: comunidade de aprendizado de m√°quina
  - *Popula√ß√£o estimada*: 2% de todos os estat√≠sticos
  - *Forma funcional*: $f(x)$ √© desconhecida e complexa
]
]

.pull-right-1[
```{r, echo=FALSE, out.width='70%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Breiman.jpg')
```
<br>
.center[**Leo Breiman**]
.center[Fonte: [en.wikipedia.org](https://en.wikipedia.org/wiki/Leo_Breiman)]
]

.content-box-blue[.center[Statistical modeling: The two cultures `r Citep(myBib, "breiman2001statistical")`.]
]

<!-- Slide XX -->
---
name: AM
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Aprendizado de M√°quina** <br> (*Machine Learning*)]

<!--Slide 6 -->
---
# Aprendizado de M√°quina (*Machine Learning*)

**Hist√≥ria:**
- Surgiu em 1959;
- Arthur Lee Samuel: Cunhou pela primeira vez o termo *Machine Learning*; e
- Manuscrito: .blue[*Some Studies in Machine Learning Using the Game of Checkers*] `r Citep(myBib, "samuel1959some", .opts = list(hyperlink = "to.doc", super = TRUE))`.

--

.pull-left[
.blockquote[
**Defini√ß√£o:** <br>
√â um .content-box-red[subconjunto de intelig√™ncia artificial] que frequentemente usa t√©cnicas estat√≠sticas para dar aos computadores a capacidade de .content-box-red["aprender"] com dados, sem serem explicitamente programados. <br>

.tr[
‚Äî (Parafraseado de Arthur Lee Samuel, 1959)
]
]
]

.pull-right[
Arthur Samuel demonstrates how machine <br> learning can be used to play checkers in 1962.
```{r, echo=FALSE, out.width='80%', fig.align='left', fig.cap='', dpi=600}
knitr::include_graphics('fig/ArtSam.jpg')
```
.left[.footnote[Fonte: [artsandculture.google.com](https://artsandculture.google.com/asset/arthur-samuel-demonstrates-how-machine-learning-can-be-used-to-play-checkers-in-1962-ibm-watson-media/vgH46mpas8dL4g)]]
]

<!--Slide 7 -->
---
# Aprendizado de M√°quina (*Machine Learning*)

.pull-left[
.blockquote[
**Tom Mitchel**<br>
Pode-se afirmar que um programa de computador aprende uma
**Experi√™ncia E** a respeito de uma **Tarefa T** e alguma medida de **Desempenho P**, se seu desempenho em *T*, medido por *P*, melhora com a experi√™ncia *E*.
]
]

.pull-right[
.blockquote[
**Aur√©lien G√©ron**<br>
√â a ci√™ncia (e arte) de programar computadores de tal forma que eles aprendam a partir de dados `r Citep(myBib, "geron2017")`.
]
]

.pull-left-2[
**Tarefa T**: Predizer alguma vari√°vel biom√©trica (ex.: biomassa);

**Medida de Desempenho P**: Alguma fun√ß√£o custo (ex.: RMSE); e

**Experi√™ncia de treinamento E**: Conjunto de exemplos da vari√°vel resposta (ex.: biomassa) e suas potenciais preditoras (ex.: D, H, $\rho$).
]

<!-- Slide XX -->
---
name: TA
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font180[**Tipos de Aprendizagem** <br> (*Supervisionada vs n√£o-supervisionada*)]

<!--Slide 8 -->
---
# Tipos de Aprendizagem

.pull-left-4[
.blockquote[
.content-box-blue[**Aprendizagem Supervisionada:**]

- **Objetivo principal**:

Dado as medidas $\left(x_1, y_1\right)$, . . . , $\left(x_n, y_n\right)$, o objetivo √© estimar uma fun√ß√£o $f(x)$ para predizer um novo valor de $y$ baseado em $x$.

- **Tipos de problemas**: classifica√ß√£o e regress√£o.

- **Vari√°vel resposta**: Existe (dados rotulados).
]]

--

.pull-right-4[
.blockquote[
.content-box-blue[**Aprendizagem n√£o-supervisionada:**]
- **Tipos de problemas**: agrupamento, redu√ß√£o de dimensionalidade e associa√ß√£o.
    - **Objetivo principal**: Descobrir estruturas subjacentes;
    - **Vari√°vel resposta**: N√£o existe (dados n√£o rotulados)
]]


<!--Slide 9 -->
---
name: tipos
# Tipos de Aprendizagem

```{r, echo=FALSE, out.width='80%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/ML.png')
```
.left[.footnote[Fonte: O Autor.]]

<!--Slide 10 -->
---
# A ideia de "Supervisionar"...

.blockquote[
**Em um conjunto de dados...** <br>

(..) para cada observa√ß√£o de preditora(s), $x_{i}$ (i = 1, ..., n), existe uma resposta associada $y_{i}$ `r Citep(myBib, "james2013introduction", .opts = list(max.names = 1, longnamesfirst = F))`.
] <br>

\[
\normalsize
\underbrace{
\overbrace{\begin{bmatrix}
x_{11} & x_{12} & \cdots & x_{1n} \\
x_{21} & x_{22} & \cdots & x_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{n1} & x_{n2} & \cdots & x_{nn}
  \end{bmatrix}
    }^{\mathbf{X}}
    }_{\mathbf{Preditoras}}
\underbrace{
\overbrace{
  \begin{bmatrix}
    y_1     \\
    y_2     \\
    \vdots  \\
    y_n     \\
  \end{bmatrix}
    }^{\mathbf{y}}
    }_{\mathbf{Resposta}}
\]

.blockquote[
**O papel de Supervisor...** <br>
A ideia √© que cada $y_{i}$ exer√ßa um papel de .content-box-red[‚ÄúProfessor‚Äù], respons√°vel por .content-box-red[‚ÄúSupervisionar‚Äù] o processo de aprendizagem de uma
fun√ß√£o $f(x)$ `r Citep(myBib, "hastie2016elements")`.
]

<!--Slide 11 -->
---
# Um conjunto de dados...

.pull-left[
.center[**Cubagem por Smalian**] 

.scroll-box-20[
```{r, echo=FALSE, eval=TRUE, message=FALSE}
library(kableExtra)
data <- data.table::fread("R-scripts/Cedrela.csv")

data %>% kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed"), font_size = 18)
```
]]
.pull-right[
.center[**Terminologias**] 

.blockquote[
1. Comunidade de aprendizado de m√°quina:
- **Inst√¢ncias/exemplos**: dados individuais.
- **Atributos/caracter√≠sticas/features:**
    - Caracter√≠sticas mensur√°veis de uma inst√¢ncia.
- **Vari√°vel resposta/labels/classe**: 
    - Vari√°vel de interesse para predi√ß√£o.

*Tipos de atributos*: bin√°rios, categ√≥ricos, num√©ricos
]]

<!--Slide 12 -->
---
# At√© aqui...
<br>

.pull-left-2[
.blockquote[
- **Motivos para fazer regress√£o**: pr√°ticos e estat√≠sticos;

- **Duas Culturas no uso de ME**: DMC e .content-box-red[AMC];

- **Algorithmic modeling culture**: relaciona-se ao campo de .content-box-red[Aprendizado de M√°quina];

- **Tipos de Aprendizado**: .content-box-red[Supervisionado] e N√£o-Supervisionado;

- **Aprendizado Supervisionado**: estimar uma fun√ß√£o $f(x)$ para predizer um novo valor de $y$ baseado em $x$. Se $y$ for um n√∫mero real (n√∫merico) tem-se um .content-box-red[problema de regress√£o].
]
]<br>

.center[
.font150[
Quais algoritmos existentes para estimar $\Large{f\left(x\right)}$?
]
]

<!-- Slide XX -->
---
name: AAS
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font180[**Algoritmos de Aprendizado <br> Supersivionado**]

<!--Slide 13 -->
---
# Algoritmos de AS
**- Alguns dos principais algoritmos para problemas de regress√£o:**
.pull-left[
```{r, echo=FALSE, out.width='110%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Tec.png')
```
.left[.footnote[Fonte: O Autor.]]
]

--

.pull-rigth[
.center[**Pacote CARET** <br>

Mais de 200 algoritmos para aprendizado supervisionado.

`r Citep(myBib, c("kuhn2013applied", "R-caret"))` <br>

Web page: [CARET Package](https://topepo.github.io/caret/index.html)

]
]

<!--Slide 14 -->
---
name: RT
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Regression Tree**]

.font150[(.red[C]lassification .red[A]nd .red[R]egression .red[T]rees - CART)]

`r Citep(myBib, "breiman1984classification", .opts = list(max.names = 1, longnamesfirst = F))`

<!--Slide 15-->
---
# Regression Tree (CART)

.pull-left-1[
```{r, echo=FALSE, out.width='80%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/CART-Book.jpg')
```
.center[Fonte: [www.amazon.com.br](https://www.amazon.com.br/Classification-Regression-Trees-Leo-Breiman/dp/0534980546)]
]

.pull-right-2[
**Informa√ß√µes gerais:**
- **CART**: algoritmo mais famoso;
- **Significado:** .red[C]lassification .red[A]nd .red[R]egression .red[T]rees;
- **Proposto**: `r Citet(myBib, "breiman1984classification", .opts = list(max.names = 1, longnamesfirst = F))`;
- **Problemas**: Classifica√ß√£o e Regress√£o; e
- **Hiperpar√¢metro tuning**: .red[cp] (par√¢metro de complexidade).

]

<!--Slide 16 -->
---
# Regression Tree (CART)

.pull-left-2[
.blockquote[
- **Qual a ideia principal:**

  - Realizar **particionamentos recursivos** no espa√ßo das covari√°veis, e ajustar um **modelo constante** da vari√°vel resposta em cada parti√ß√£o. <br>


- **Motivo**:
  - Encontrar parti√ß√£o em que as observa√ß√µes sejam mais **homog√™neas** o poss√≠vel para a **vari√°vel resposta**. <br>


- **Covari√°veis**: categ√≥ricas, dicot√¥micas, discretas ou cont√≠nuas.
]
]

<!--Slide 17 -->
---
# Regression Tree (CART)

.pull-left-3[
.blockquote[
**Estrutura:** <br>

1) **N√≥ raiz** (*root node*): $R_{1}$

2) **N√≥ intermedi√°rio** (*intermediate node*): $I_{2}$, $I_{3}$ e $I_{7}$

3) **N√≥ terminal** ou **folha** (*leaf* or *terminal node*): $T_{4}$, $T_{5}$, $T_{6}$, $T_{8}$ e $T_{9}$

4) **Divis√µes** (*splits*): $d_{1}$, $d_{2}$, $d_{3}$ e $d_{4}$ (condi√ß√µes "se-ent√£o")
]

--

.pull-bottom[
.blockquote[
- **Etapas do aprendizado**:

  1) Crescimento de uma √°rvore completa (adulta) at√© algum crit√©rio de parada; e
  
  2) Poda da √°rvore (overfitting).
]
]


]

.pull-right-3[
.center[**Uma √°rvore de regress√£o...**]

```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/CART1.png')
```
.left[.footnote[Fonte: Adaptado de Breiman et al. (1984).]]
]

<!--Slide 15 -->
---
# Regression Tree: Como uma √°rvore cresce?

.panelset[
.panel[.panel-name[Dados]
.pull-left[

.scroll-box-20[
```{r, echo=FALSE, eval=TRUE, message=FALSE}
data <- data.table::fread("R-scripts/Cedrela.csv")

data %>% kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed"), font_size = 18)

```
]]
.pull-right[
**Meta**: Estimar uma fun√ß√£o de regress√£o $f(x)$ usando o algoritmo CART para predizer o volume $\left(\normalsize V = f(D,H)\right)$

**Foco**: Como √© o processo de crescimento de uma √°rvore CART?

]
]

.panel[.panel-name[CART]
.pull-left[
```{r, echo=FALSE, fig.width=5, fig.height=3, warning=FALSE, fig.align='center', fig.cap='√Årvore CART (rpart/cp = 0/minsplit = 20)', dpi=600, eval=TRUE, message=FALSE}
set.seed(1)
data2 <- data %>% select(-Arv)

tree <- rpart(V ~ ., 
              data = data2, 
              method="anova", 
              control = rpart.control(cp = 0, minsplit = 20))

rattle::fancyRpartPlot(tree,
                       yesno=2,
                       split.col="black",
                       nn.col="black",
                       caption="",
                       palette="Set2",
                       branch.col="black",
                       digits = 4)

# rpart.plot(tree, box.palette="RdBu", shadow.col="gray", nn=TRUE, digits = 4)
```
*minsplit* = M√≠nimo de 20 observa√ß√µes p/ tentar uma divis√£o
]

.pull-right[
.scroll-box-20[
.shadow[
**1) In√≠cio**
- N√≥ raiz (todas inst√¢ncias)/(**n = 32**)
- C√°lculos: 
  - M√©dia aritm√©tica da resposta (melhor ``chute''); 
  **5.724 m`r knitr::asis_output("\U00B3")`**
  
  - Soma de Quadrados de Res√≠duos (SQR). **326.19 (m`r knitr::asis_output("\U00B3")`)`r knitr::asis_output("\U00B2")`**

\begin{equation}
SQR = \sum_{i=1}^{n}(y_{i} - \hat{f_{m}}(x_{i}))^{2}
\end{equation}

$\hat{f_{m}}(x_{i})$: predi√ß√£o na regi√£o $m$ em que a i-√©sima observa√ß√£o √© alocada.
]

.shadow[
**2) Primeira divis√£o** 
- Qual divis√£o selecionar?
  - Maior redu√ß√£o da SQR: Qual vari√°vel e ponto de corte?
  
  1) Vari√°vel escolhida: **D (di√¢metro)**
  
  2) Ponto de corte: **95.97cm**
  
- Qual SQR p/ n√≥s filhos?
    - $SQR_{N_{2}}$: 
    **64.39 (m`r knitr::asis_output("\U00B3")`)`r knitr::asis_output("\U00B2")`**
    - $SQR_{N_{3}}$: 
    **93.88 (m`r knitr::asis_output("\U00B3")`)`r knitr::asis_output("\U00B2")`**
    
\begin{equation}
{\Delta R(s,t)} = R(t) - (R(t_L) + R(t_R)) \\
\end{equation}

 = **326.19280 - (64.39354 + 93.87834)**
 
 = **`r tree$frame$dev[1] - (tree$frame$dev[2] + tree$frame$dev[5])` (m`r knitr::asis_output("\U00B3")`)`r knitr::asis_output("\U00B2")`**

]

.shadow[
**3) Segunda divis√£o**
   
  1) Vari√°vel escolhida: **D (di√¢metro)**
  
  2) Ponto de corte: **79.74cm**
  
- Qual SQR p/ n√≥s filhos?
    - $SQR_{N_{4}}$: 
    **17.41 (m`r knitr::asis_output("\U00B3")`)`r knitr::asis_output("\U00B2")`**
    - $SQR_{N_{5}}$: 
    **13.90 (m`r knitr::asis_output("\U00B3")`)`r knitr::asis_output("\U00B2")`**
    
\begin{equation}
{\Delta R(s,t)} = R(t) - (R(t_L) + R(t_R)) \\
\end{equation}

 = **64.39354 - (17.40637 + 13.89782)**
 
 = **`r tree$frame$dev[2] - (tree$frame$dev[3] + tree$frame$dev[4])` (m`r knitr::asis_output("\U00B3")`)`r knitr::asis_output("\U00B2")`**

]   

.shadow[
.center[**Resumindo**]

O uso de cp=0 permitiu o crescimento de uma √°rvore sem restri√ß√µes, comumente chamada "√°rvore adulta". Tamb√©m, minsplit = 20 imp√¥s a condi√ß√£o de existir no m√≠nimo 20 observa√ß√µes em um n√≥ para que uma divis√£o fosse tentada.

- *Estrutura*: 
    - Duas divis√µes bin√°rias;
    - Tr√™s n√≥s terminais (*);
    - Quatro regras do tipo if-then (Se ent√£o); e
    - Somente a vari√°vel D (di√¢metro) foi escolhida.
]
  
]]]

.panel[.panel-name[Regras]

```{r, echo=FALSE, out.width='40%', fig.align='center', fig.cap='', dpi=600}
print(tree)
rpart.rules(tree, cover = TRUE)
```

]

.panel[.panel-name[SQR-N1]

.pull-left[

.scroll-box-20[
```{r, echo=FALSE, eval=TRUE, message=FALSE}
library(kableExtra)
data <- data.table::fread("R-scripts/Cedrela.csv")

data %>% 
  arrange(D) %>%
  mutate("yi-fm" = V-mean(data$V)) %>%
  mutate("(yi-fm)¬≤" = (V-mean(data$V))^2) %>%
  janitor::adorn_totals("row") %>%
  #rmarkdown::paged_table()
  kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options =
                  c("striped", "hover", "condensed"), 
                font_size = 18) %>%
  row_spec(33, bold = T, 
           color = "white", background = "black") %>%
  row_spec(25, bold = T,
           color = "white", background = "orange") %>%
  row_spec(26, bold = T,
           color = "white", background = "orange")
```

]]

.pull-right[
- **1) In√≠cio**:

$\bar{V}$ = `r mean(data$V)`;

$SQR_{N_{1}}$ = `r sum((data$V-mean(data$V))^2)`

Ponto de corte: (95.49 + 96.45)/2 = **95.97cm**
]
]

.panel[.panel-name[SQR-N2-N3]

.pull-left[

.scroll-box-20[
```{r, echo=FALSE, eval=TRUE, message=FALSE}
df <- data %>% arrange(D) %>%
  filter(D < 95.97) %>%
  mutate("yi-fm" = V-mean(V)) %>%
  mutate("(yi-fm)¬≤" = (V-mean(V))^2)

df %>%
  janitor::adorn_totals("row") %>%
  kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options =
                  c("striped", "hover", "condensed"),
                font_size = 18) %>%
  row_spec(26, bold = T,
           color = "white", background = "black") %>%
  row_spec(16, bold = T,
           color = "white", background = "orange") %>%
  row_spec(17, bold = T,
           color = "white", background = "orange")
```

]]

.pull-right[
```{r, echo=FALSE, eval=TRUE, message=FALSE}
df2 <- data %>% arrange(D) %>%
  filter(D >= 95.97) %>%
  mutate("yi-fm" = V-mean(V)) %>%
  mutate("(yi-fm)¬≤" = (V-mean(V))^2)

df2 %>% 
  janitor::adorn_totals("row") %>%
  kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options =
                  c("striped", "hover", "condensed"),
                font_size = 18) %>%
  row_spec(8, bold = T,
           color = "white", background = "black")
```

.pull-bottom[
Ponto de corte: **79.74cm**

$SQR_{N_{2}}$ = `r sum((df$V-mean(df$V))^2)`;
$\bar{V}$ = `r mean(df$V)`

$SQR_{N_{3}}$ = `r sum((df2$V-mean(df2$V))^2)`;
$\bar{V}$ = `r mean(df2$V)`

]
]
]

.panel[.panel-name[SQR-N4-N5]

.pull-left[

.scroll-box-20[
```{r, echo=FALSE, eval=TRUE, message=FALSE}
df4 <- data %>% arrange(D) %>%
  filter(D < 79.74) %>%
  mutate("yi-fm" = V-mean(V)) %>%
  mutate("(yi-fm)¬≤" = (V-mean(V))^2) 

df4 %>%
  janitor::adorn_totals("row") %>%
  kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options =
                  c("striped", "hover", "condensed"),
                font_size = 18) %>%
  row_spec(17, bold = T,
           color = "white", background = "black")
```

]

.pull-bottom[
Ponto de corte: **79.74cm**

$SQR_{N_{4}}$ = `r sum((df4$V-mean(df4$V))^2)`;
$\bar{V}$ = `r mean(df4$V)`
]
]

.pull-right[
```{r, echo=FALSE, eval=TRUE, message=FALSE}
df5 <- data %>% arrange(D) %>%
  filter(D >= 79.74 & D < 95.97) %>%
  mutate("yi-fm" = V-mean(V)) %>%
  mutate("(yi-fm)¬≤" = (V-mean(V))^2)

df5 %>%
  janitor::adorn_totals("row") %>%
  kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options =
                  c("striped", "hover", "condensed"),
                font_size = 18) %>%
  row_spec(10, bold = T,
           color = "white", background = "black")
```

.pull-bottom[

$SQR_{N_{5}}$ = `r sum((df5$V-mean(df5$V))^2)`;
$\bar{V}$ = `r mean(df5$V)`

]
]
]

.panel[.panel-name[Regi√µes]

```{r, echo=FALSE, eval=TRUE, fig.width=7, fig.height=2, dpi=600}
data <- data.table::fread("R-scripts/Cedrela.csv")

r1 <- data %>% 
  ggplot() + 
    geom_point(data=data, aes(x=D, y=V, color=ifelse(data$D >= tree$splits[1,4], "red", "black")), size=1) +
  geom_vline(xintercept=tree$splits[1,4], colour="red", linetype="dotted") +
  scale_colour_manual(values = c("black", "red")) +
  geom_text(aes(x=tree$splits[1,4], y=15, 
                label="D >= 95.97"), colour="red", 
            angle=90, vjust = 1.2, size = 4) +
  theme(legend.position="none")

r2 <- r1 + 
  geom_point(data=data, aes(x=D, y=V, colour=ifelse(D < tree$splits[3,4], "blue", ifelse(D >= tree$splits[1,4], "red", "black"))), size=1) +
  scale_colour_manual(values = c("blue", "black", "red"))+
  geom_vline(xintercept=tree$splits[3,4], colour="blue", linetype="dotted") +
    geom_text(aes(x=tree$splits[3,4], y=15, 
                label="D >= 79.74"), colour="blue", 
            angle=90, vjust = 1.2, size = 4) +
  theme(legend.position="none")

r3 <- r2 + 
  geom_text(aes(x=65, y=10, label="R4 \n Vest. = 3.65"), colour="black", 
            vjust = 1.2, size = 2) +
  geom_text(aes(x=87, y=10, label="R5 \n Vest. = 6.05"), colour="blue", 
            vjust = 1.2, size = 2) +
  geom_text(aes(x=123, y=10, label="R3 \n Vest. = 10.05"), colour="red", 
            vjust = 1.2, size = 2)

ggpubr::ggarrange(r1, r2, r3, ncol=3,
                  labels=c("", ""),
                  font.label=list(size=30))
```

]

.panel[.panel-name[f(x)]
.pull-left-2[
```{r, echo=FALSE, fig.align='center', fig.width=5, fig.height=3, fig.cap='', dpi=600, eval=TRUE, warning=FALSE, message=FALSE}

r2 + geom_line(aes(x = D, y = predict(tree)))

```
]
]
]

<!-- Slide XX -->
---
# Underfitting e Overfitting
<br>
S√£o conceitos estat√≠sticos relacionados ao ajuste dos modelos.

- **Subajuste** (*Underfitting*)
  - Quando o modelo aprendido produz **predi√ß√µes ruins** no **conjunto de treinamento**, ou seja o modelo √© simples demais para explicar os dados usados no processo de aprendizado.

- **Sobreajuste** (*Overfitting*)
  - Quando o modelo aprendido produz **boas predi√ß√µes** no **conjunto de treinamento** (se ajusta demais aos dados de treino), por√©m **n√£o generaliza bem para novos dados**.

**Ideal**: Encontrar um modelo intermedi√°rio entre subajuste e superajuste!

<!-- Slide XX -->
---
# Underfitting e Overfitting
<br>
√Årvores de regress√£o t√™m tend√™ncia de sobreajustar.

.pull-left[
```{r, echo=FALSE, fig.height=.5, fig.width=.5, fig.cap=""}
bio <- data.table::fread("R-scripts/AGB.csv")

rpart2 <- rpart(AGB ~ D,
                data = bio,
                control = list(cp = 0, maxdepth = 10,
                               minbucket = 1, minsplit = 5))

gg1 <- plot_ly(bio, x = ~D, y = ~AGB, 
               name = 'AGB', 
               type = 'scatter', 
               mode = 'markers') %>% 
  layout(title="",
         font = list(size = 14),
         xaxis=list(title="Di√¢metro (cm)"),
         yaxis=list(title="Biomassa A√©rea Total (kg)"),
          annotations = list(
            x = 50,
            y = 70000, 
            text = "Overfitting",
            showarrow = FALSE,
             font = list(color = '#264E86',
                         family = 'sans serif',
                         size = 20))) %>%
  add_lines(y = ~predict(rpart2), 
            name = 'AGBest', 
            mode = 'lines')

htmltools::tagList(gg1)

```

]

.pull-right[
```{r, echo=FALSE, out.width='80%', fig.cap=""}
rpart3 <- rpart(AGB ~ D, 
                data = bio, 
                control = list(cp = 0, maxdepth = 2, 
                               minbucket = 1, minsplit = 5))

gg2 <- plot_ly(bio, x = ~D, y = ~AGB, 
               name = 'AGB', 
               type = 'scatter', 
               mode = 'markers') %>% 
  layout(title="",
         font = list(size = 14),
         xaxis=list(title="Di√¢metro (cm)"),
         yaxis=list(title="Biomassa A√©rea Total (kg)"),
          annotations = list(
            x = 50,
            y = 70000, 
            text = "Underfitting",
            showarrow = FALSE,
             font = list(color = '#264E86',
                         family = 'sans serif',
                         size = 20))) %>%
  add_lines(y = ~predict(rpart3), 
            name = 'AGBest', 
            mode = 'lines')

htmltools::tagList(gg2)
```

]

<!-- Slide XX -->
---
# Overfitting: como minimizar?
<!-- C√≥digo adaptado de Bradley boehmke. Dispon√≠vel em: link: https://github.com/bradleyboehmke/random-forest-training/blob/master/docs/slides-source.Rmd -->

.pull-left-4[
Duas estrat√©gias principais:

**1) Parada antecipada**

  - Restringir a profundidade m√°xima da √°rvore (maxdepth); e
  
  - Restringir o n√∫mero m√≠nimo de observa√ß√µes em qualquer n√≥ terminal (minbucket).

]

.pull-right-4[
```{r, echo=FALSE, out.width='100%', cache=TRUE}
library("gganimate")
library("gifski")
library("transformr")

bio <- data.table::fread("R-scripts/AGB.csv")
maxdepth <- 1:12
results <- data.frame(NULL)

for(i in maxdepth) {
 ctrl <- list(cp = 0, maxdepth = i, 
              minbucket = 1, minsplit = 5)
 fit <- rpart(AGB ~ D, data = bio, control = ctrl) 
 
 pred <- mutate(bio, maxdepth = maxdepth[i])
 pred$pred <- predict(fit, bio)
 results <- rbind(results, pred)
   
}

p <- results %>%
  ggplot(aes(D, pred)) +
  geom_point(aes(D, AGB), alpha = .3, size = 2) +
  geom_line(color = "red", size = 1) +
  ylab("Biomassa A√©rea Total (kg)") + 
  xlab("Di√¢metro (cm)") + 
  labs(title = 'Profundidade m√°xima: {frame_time}') +
  transition_time(maxdepth)
  animate(p, renderer = gifski_renderer(), device = "png")
```  

]

<!-- Slide XX -->
---
# Overfitting: como minimizar?

.pull-left-4[
Duas estrat√©gias principais:

**1) Parada antecipada**

  - Restringir a profundidade m√°xima da √°rvore (maxdepth); e
  
  - Restringir o n√∫mero m√≠nimo de observa√ß√µes em qualquer n√≥ terminal (minbucket).

]

.pull-right-4[
```{r, echo=FALSE, out.width='100%', cache=TRUE}
minbucket <- 1:20
results <- data.frame(NULL)

for(i in minbucket) {
 ctrl <- list(cp = 0, maxdepth = 10, 
              minbucket = i, minsplit = 5)
 fit <- rpart(AGB ~ D, data = bio, control = ctrl) 
 
 pred <- mutate(bio, minbucket = minbucket[i])
 pred$pred <- predict(fit, bio)
 results <- rbind(results, pred)
   
}

p <- results %>%
  ggplot(aes(D, pred)) +
  geom_point(aes(D, AGB), alpha = .3, size = 2) +
  geom_line(color = "red", size = 1) +
  ylab("Biomassa A√©rea Total (kg)") + 
  xlab("Di√¢metro (cm)") + 
  labs(title = 'N√∫mero m√≠nimo de observa√ß√µes no n√≥ terminal: {frame_time}') +
  gganimate::transition_time(minbucket)
  animate(p, renderer = gifski_renderer(), device = "png")
```  

]

<!-- Slide XX -->
---
# Overfitting: como minimizar?
<br>

Duas estrat√©gias principais:

.pull-left[
**2) Poda custo complexidade**

  - Cresce uma √°rvore adulta (complexa).
  
  - As parti√ß√µes s√£o sucessivamente desfeitas (podada) para encontrar uma sub√°rvore √≥tima; e
  
  - Fun√ß√£o de custo-complexidade: $R_{Œ±}(T) = R(T) + Œ±|T|$
]

.pull-right[

.blockquote[
.center[**Termos**]

  $T$: representa uma √°rvore;
  
  $|T|$: n√∫mero de n√≥s terminais;
  
  $R(T)$: soma de quadrados de res√≠duos; e
  
  $Œ±$: Par√¢metro custo complexidade (controla complexidade). Hiperpar√¢metro tuning.
  
  Se $Œ± = 0$ $\rightarrow$ a melhor √°rvore ser√° a maior √°rvore.

  **Valida√ß√£o cruzada**: Usada para encontrar o melhor $Œ±$ (a melhor sub√°rvore).
]
]

<!-- Slide XX -->
---
# Regression Tree: pontos fortes e fracos...

.pull-left-4[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/RT-PF.png')
```
.left[**Fonte**: O Autor.]
]

--

.pull-right-4[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/RT-PFr.png')
```
]

<!-- Slide XX -->
---
name: bag
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Bagging**]

.font150[(.red[B]ootstrap .red[Agg]regat.red[ing])]

`r Citep(myBib, "breiman1996bagging", .opts = list(max.names = 1, longnamesfirst = F))`

<!-- Slide 17 -->
---
# Bagging

.pull-left-1[
```{r, echo=FALSE, out.width='80%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Breiman1996.png')
```
.center[Fonte: [link.springer.com](https://link.springer.com/article/10.1007/BF00058655)]

]

.pull-right-2[
**Informa√ß√µes gerais:**
- **Bagging**: um dos primeiros algoritmo de conjunto (ensemble);
- **Significado:** .red[B]ootstrap .red[Agg]regat.red[ing];
- **Proposto**: `r Citet(myBib, "breiman1996bagging")`;
- **Problemas**: Classifica√ß√£o e Regress√£o; e
- **Hiperpar√¢metro tuning**: .red[nbagg] (n√∫mero de replica√ß√µes de bootstrap);
]


<!--Slide 18 -->
---
# Bagging

.pull-left-2[
.blockquote[
- **Ideia principal:**

  - Ajustar m√∫ltiplas vers√µes de um modelo preditivo, e depois agreg√°-las, para obter uma √∫nica predi√ß√£o combinada `r Citep(myBib, "breiman1996bagging")`.<br>


- **Motivos**:
  - Reduzir a vari√¢ncia de um m√©todo de predi√ß√£o, como as √°rvores de regress√£o, e promover melhorias substanciais na acur√°cia `r Citep(myBib, "james2013introduction", .opts = list(max.names = 1, longnamesfirst = F))`.<br>
  
  
- **Aprediz de base**:
  - M√©todos de alta vari√¢ncia (e baixo vi√©s) (ex.: √°rvores de regress√£o). <br>
  
    <!-- - **Vantagens**: Ajuda a reduzir a varia√ß√£o, minimizar o overfitting (sobreajuste) e, por conseguinte, melhorar o desempenho preditivo. <br> -->
]
]


---
# M√©todo Bootstrap

.pull-left-3[
.blockquote[
√â um **m√©todo de reamostragem** que consiste em **produzir replica√ß√µes** de tamanho $n$, com mesmo tamanho do conjunto de aprendizado, por **amostragem aleat√≥ria com reposi√ß√£o** `r Citep(myBib, "gama2015extraccao", .opts = list(max.names = 1, longnamesfirst = F))`.
]
]

.pull-bottom[
```{r, echo=FALSE, out.width='70%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Bootstrap.png')
```
.footnote[Fonte: Adaptado de [texample.net](https://texample.net/tikz/examples/bootstrap-resampling/)
]

]


<!--Slide XX -->
---
# Bagging (Bagged Trees)

.pull-left-2[
.blockquote[
O bagging pode ser usado para combinar **√°rvores modelos** `r Citep(myBib, "witten2017data", .opts = list(max.names = 1, longnamesfirst = F))`, e mais comumente **√°rvores de decis√£o** `r Citep(myBib, "james2013introduction", .opts = list(max.names = 1, longnamesfirst = F))`.
]
]

--

.pull-right-2[
**Cada √°rvore crescida possui alta vari√¢ncia, mas baixo vi√©s.**
.blockquote[
**No caso de regress√£o (usando √°rvores)...**

**Passo 1** - Dado um conjunto de treinamento original $L$ de tamanho $n$, gerar uma amostra *bootstrap* $bi$ de tamanho $n$;

**Passo 2** - Treinar um modelo de √°rvore de regress√£o completamente crescida (profundas e n√£o podadas) usando a amostra *bootstrap* $bi$; e

**Passo 3** - Salvar o modelo preditivo.

Esse procedimento pode ser realizado $B$ vezes. Em que: $B$ = n√∫mero de amostras bootstrap.
]
]


<!--Slide XX -->
---
# Bagging (Bagged Trees)

```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Bagg.png')
```

\begin{equation}
{\hat{f}_{(bag)}(x)} = \frac{1}{B}\displaystyle\sum\limits_{b=1}^B\hat{f}^{*b}(x)
\label{eq:avBAG}
\end{equation}


<!--Slide 19 -->
---
# Bagging (Bagged Trees)

.panelset[
.panel[.panel-name[Dados]
.pull-left-1[

.scroll-box-20[
```{r, echo=FALSE, eval=TRUE}
data <- data.table::fread("R-scripts/Cedrela.csv")

data %>% kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed"), font_size = 18)

```

]]

.pull-right-2[
**Implementa√ß√£o no R** (exemplo de brinquedo!)

```{r, echo=TRUE, eval=TRUE}
library(ipred)

data <- data.table::fread("R-scripts/Cedrela.csv")

set.seed(1)
bagTr <- bagging(V ~ D + H, data = data, 
                 nbagg = 10, # (Recomenda√ß√£o: 50-250)
                 coob = F,   # out-of-bag estimate
                 control = rpart.control(
                   cp = 0, minsplit = 20, maxdepth = 30))
```

**Out-of-Bag**: observa√ß√µes n√£o sorteadas na amostra bootstrap $b_{i}$. Portanto, n√£o usadas para aprender a $f(x)$.

**Out-Of-Bag estimate**: √â o erro m√©dio de predi√ß√£o calculado usando as amostras Out-of-Bag.

]
]

.panel[.panel-name[Bagging]

.pull-left-2[
```{r, echo=FALSE, eval=TRUE, out.width='75%', out.height='10%'}
par(mfrow = c(2, 5))

nbag <- 1:length(bagTr$mtrees)

for(i in nbag) {
rpart.plot(bagTr$mtrees[[i]]$btree, 
           box.palette="RdBu", 
           shadow.col="gray", 
           nn=TRUE, 
           digits = 4,
           main = paste0("√Årvore: ", i)
           )
}

```
]

.pull-right-1[
**Obs.**: Este exemplo √© apenas para intui√ß√£o do m√©todo. Portanto, no bagging cada √°rvore (aprendiz de base) √© crescida sem poda e profunda (alta complexidade).
]

]

.panel[.panel-name[f(x)]

.pull-left-2[
```{r, echo=FALSE, fig.width=5, fig.height=3, fig.cap="", message=FALSE}
df <- data.table::setDF(data)

predbag <- 1:length(bagTr$mtrees)

for(i in predbag) { 
  new <- predict(bagTr$mtrees[[i]]$btree, newdata=df)
  df[ , ncol(df) + 1] <- new
  colnames(df)[ncol(df)] <- paste0("Tree", i)
}

df <- df %>% 
  mutate(Bagging = rowMeans(select(., starts_with("Tree")))) %>%
  tidyr::pivot_longer(starts_with(c("Tree", "Bag")),
                    names_to = "Tree",
                    values_to = "Pred") %>%
  mutate_if(is.character, as.factor) 

gg3 <- df %>%
  filter(Tree != "Bagging") %>%
  group_by(Tree) %>% 
  plot_ly(x = ~D, y = ~V, colors = "Paired",
          type = 'scatter', mode = 'markers') %>% 
  add_lines(y = ~ Pred, color = ~ Tree, mode = 'lines') %>%
  layout(title="",
         font = list(size = 14),
         xaxis=list(title="Di√¢metro (cm)"),
         yaxis=list(title="Volume (m3)")) %>%
  add_lines(data = subset(df, Tree == 'Bagging'),
            y = ~ Pred, mode = 'lines',
            name = 'Bagging',
            line = list(color = 'black', 
                        width = 4)) 

htmltools::tagList(gg3)

# cols <- c("Tree1"="#a6cee3",
#           "Tree2"="#1f78b4",
#           "Tree3"="#b2df8a", 
#           "Tree4" = "#33a02c",
#           "Tree5"="#fb9a99",
#           "Tree6"="#e31a1c",
#           "Tree7"="#fdbf6f", 
#           "Tree8" = "#ff7f00",
#           "Tree9"="#cab2d6",
#           "Tree10"="#ffff99", 
#           "Bag" = "black"
#           )
# df %>%
#   ggplot() +
#   geom_point(aes(x=D, y=V)) +
#   geom_line(aes(x=D, y=Pred,
#              colour=Tree)) +
#   scale_color_manual(name="Tree",values=cols) +
#   geom_line(data = subset(df, Tree == 'Bag'),
#             aes(x=D, y=Pred),
#             size = 1.5, linetype = 'solid', color = 'black') +
#     theme(legend.title=element_blank())

```
]
]
]

<!--Slide XX -->
---
# Bagging: pontos fortes e fracos...

.pull-left-4[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Bagging-PF.png')
```
.left[.footnote[**Fonte**: O Autor.]]
]

--

.pull-right-4[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Bagging-PFr.png')
```
]

<!--Slide XX -->
---
name: rf
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Random Forest**]

`r Citep(myBib, "breiman2001random", .opts = list(max.names = 1, longnamesfirst = F))`

<!-- Slide XX -->
---
# Random Forest

.pull-left-1[
```{r, echo=FALSE, out.width='80%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Breiman2001-RF.png')
```
.center[Fonte: [link.springer.com](https://link.springer.com/article/10.1023/A:1010933404324)]

]

.pull-right-2[
**Informa√ß√µes gerais:**
- **Random Forest**: um algoritmo baseado em conjunto de √°rvores;
- **Proposto**: `r Citet(myBib, "breiman2001random")`;
- **Problemas**: Classifica√ß√£o e Regress√£o; e
- **Hiperpar√¢metro tuning**: .red[mtry] (n√∫mero de preditoras amostradas aleatoriamente como candidatas em cada divis√£o).
]

<!--Slide 18 -->
---
# Random Forest

.pull-left-6[
.blockquote[
- **Ideia principal:**

  - √â uma modifica√ß√£o substancial do *bagging*, e objetiva construir uma **cole√ß√£o de √°rvores n√£o correlacionadas** e, em seguida, calcular a m√©dia das predi√ß√µes individuais (no caso de regress√£o) `r Citep(myBib, "hastie2016elements")`.<br>


- **Motivos**:
  - Bagging **n√£o reduz de maneira ideal a vari√¢ncia** das predi√ß√µes, pois as √°rvores s√£o correlacionadas (topo da √°rvore) `r Citep(myBib, "kuhn2013applied")`.
  
  - Portanto, calcular a **m√©dia** de predi√ß√µes de **√°rvores n√£o correlacionadas** reduz de maneira ideal a **vari√¢ncia**.


- **Aprediz de base**:
  - √Årvores de regress√£o, que possui alta vari√¢ncia.
]
]

<!--Slide XX -->
---
# Random Forest

.pull-left-2[
.blockquote[
.center[**Bagging** e **Random Forest**: Diferen√ßa?]

A principal diferen√ßa entre o **Bagging** e o **Random Forest** √© a escolha do tamanho **p** no espa√ßo de preditores originais `r Citep(myBib, "james2013introduction", .opts = list(max.names = 1, longnamesfirst = F))`.
]
]

.pull-right-7[
.blockquote[

**No caso de regress√£o...**

**Passo 1** - Dado um conjunto de treinamento original $L$ de tamanho $n$, gerar uma amostra *bootstrap* $bi$ de tamanho $n$;

**Passo 2** - Treinar um modelo de √°rvore de regress√£o (profunda e n√£o podada) usando a amostra *bootstrap* $bi$. Por√©m, ao crescer cada √°rvore fazer a seguinte modifica√ß√£o:

a) Em cada n√≥ de decis√£o, selecionar um subconjunto aleat√≥rio de $m$ preditoras;

b) A melhor divis√£o ser√° escolhida dentre as $m$ preditoras candidatas.

**Passo 3** - Salvar o modelo preditivo.

]
]

---
# Random Forest

```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/RF.png')
```

<!--Slide 19 -->
---
# Random Forest

.panelset[
.panel[.panel-name[Dados]
.pull-left-1[

.scroll-box-20[
```{r, echo=FALSE, eval=TRUE}
data <- data.table::fread("R-scripts/Cedrela.csv")

data %>% kable(format= "html") %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed"), font_size = 18)

```

]]

.pull-right-2[
**Implementa√ß√£o no R** (exemplo de brinquedo!)

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(randomForest)

data <- data.table::fread("R-scripts/Cedrela.csv")

set.seed(1)
rf <- randomForest(V ~ D + H, 
             data = data,
             ntree = 10,       # n√∫mero de √°rvores (padr√£o = 500)
             mtry = 1,         # n√∫mero de preditoras (padr√£o = p/3)
             maxnodes = NULL,  # n√∫mero de n√≥s terminais
             importance = TRUE # import√¢ncia das preditoras
             )
```

]
]

.panel[.panel-name[f(x)]

.pull-left-2[
```{r, echo=FALSE, fig.width=5, fig.height=3, fig.cap="", message=FALSE}

pred <- predict(rf, newdata=data, predict.all=T)

dfrf <- pred %>% 
  as.data.frame() %>%
  bind_cols(data) %>%
  rename_at(vars(starts_with('ind')), ~ paste("Tree", 1:10)) %>%
  rename_at(vars(aggregate),~"randomForest") %>%
  tidyr::pivot_longer(starts_with(c("Tree", "rand")),
                    names_to = "Tree",
                    values_to = "Pred") %>%
  mutate_if(is.character, as.factor)

gg5 <- dfrf %>%
  filter(Tree != "randomForest") %>%
  group_by(Tree) %>% 
  plot_ly(x = ~D, y = ~V, colors = "Paired",
          type = 'scatter', mode = 'markers') %>% 
  add_lines(y = ~ Pred, color = ~ Tree, mode = 'lines') %>%
  layout(title="",
         font = list(size = 14),
         xaxis=list(title="Di√¢metro (cm)"),
         yaxis=list(title="Volume (m3)")) %>%
  add_lines(data = subset(dfrf, Tree == 'randomForest'),
            y = ~ Pred, mode = 'lines',
            name = 'randomForest',
            line = list(color = 'black', 
                        width = 4)) 

htmltools::tagList(gg5)

```
]
]
]


<!--Slide XX -->
---
# Random Forest: pontos fortes e fracos...

.pull-left-4[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/RF-PF.png')
```
.left[.footnote[**Fonte**: O Autor.]]
]

--

.pull-right-4[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/RF-PFr.png')
```
]


<!--Slide XX -->
---
name: out
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Outros (M5', ...)**]

.font100[**Existem dezenas de algoritmos por experimentar...**]


<br>.font100[**CARET: Mais de 200 algoritmos para aprendizado supervisionado.**]

<!--Slide XX -->
---
# Model Tree - M5'

.pull-left-1[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/Quilan.png')
```
.center[Fonte: [citeseerx](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.34.885)]
]

.pull-right-2[
**Informa√ß√µes gerais:**
- **Model Tree - M5'**: um algoritmo baseado √°rvores;
- **Proposto**: `r Citet(myBib, c("quinlan1992learning", "wang1997induction"))`;
- **Problema**: Regress√£o; e
- **Hiperpar√¢metro tuning**: .red[pruned]: (com poda?); .red[smoothed]: (com suaviza√ß√£o?)


O M5' foi introduzido por `r Citet(myBib, "wang1997induction")` e aprimorou o algoritmo M5 originalmente proposto por `r Citet(myBib, "quinlan1992learning")`.

]


<!--Slide XX -->
---
# Model Tree - M5' 

.pull-left-3[
.blockquote[
- **Ideia principal:**
  
  - Ao contr√°rio das √°rvores de regress√£o, as √°rvores modelos
  usam **modelos lineares** para predi√ß√µes nos **n√≥s terminais**.

  - Surgiu como uma **alternativa** √† √°rvore de regress√£o para predi√ß√£o de **vari√°veis cont√≠nuas**.

]
]

.pull-right-3[
```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/M5.png')
```
]

<br>
.center[.content-box-green[**Vejo um grande potencial desse algoritmo para Mensura√ß√£o Florestal!**]]


<!--Slide XX -->
---
# Outros algoritmos
<br>

- **k-Nearest-Neighbor** - k-NN (varia√ß√µes: wkNN)

- **Stochastic Gradient Boosting** - SGB

- **Artificial Neural Networks** - ANN

- **Support Vector Regression** - SVR

- **Extreme Gradient Boosting** - XGBoost


<!--Slide XX -->
---
name: mr
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**M√©todos de Reamostragem**]

.font100[**Como escolher dentre diversos <br> modelos de aprendizado de m√°quina?**]

<!--Slide XX -->
---
# M√©todos de Reamostragem

.pull-left-2[
.blockquote[
- **Motiva√ß√£o**

  - Precisa-se de um mecanismo para **escolher o melhor modelo** dentre diversos.


- **Melhor modelo**

  - *Grosso modo*, √© aquele que possui a melhor capacidade de **predizer novas observa√ß√µes** (menor erro de predi√ß√£o).


- **Desempenho preditivo** 

  - Assim sendo, √© fundamental **estimar o desempenho esperado** de um modelo preditivo quando usado para predizer **novas observa√ß√µes**.

]
]

.pull-right-1[

<br><br><br>Os m√©todos de reamostragem s√£o usados para estimar o desempenho de um modelo em predizer novas observa√ß√µes. <br>

A abordagem mais usual √© usar algum tipo de **valida√ß√£o cruzada**.
]

<!--Slide XX -->
---
# M√©todos de Reamostragem

<br> **Mas, antes disso...**

.blockquote[
**Tipos de conjuntos de dados...** <br>


<br>Existem tr√™s tipos de conjuntos de dados `r Citep(myBib, "witten2017data", .opts = list(max.names = 1, longnamesfirst = F))`:


- **Conjunto de treinamento** (aprendizado) 
    - Usado para construir/aprender/treinar os modelos preditivos (classifica√ß√£o ou regress√£o).
    
    
- **Conjunto de valida√ß√£o**
    - Usado para otimizar os hiperpar√¢metros dos modelos e escolher a configura√ß√£o de melhor desempenho preditivo.
    

- **Conjunto de teste**
  - Usado para estimar o desempenho preditivo final do modelo otimizado (*tuning model*). 
    
]

<!--Slide XX -->
---
# M√©todos de Reamostragem

.pull-left-2[
.blockquote[
**Tipos de valida√ß√£o cruzada...** <br>

- **Hold-out validation**
    
- **k-fold Cross-Validation**

- **Repeated k-fold cross validation**

- **Leave-One-Out Cross-Validation**
]
]

<!--Slide XX -->
---
# .font80[M√©todos de Reamostragem: Hold-out validation]
<br>

.pull-left-3[

```{r, echo=FALSE, out.width="90%"}
knitr::include_graphics("fig/Hold.png")
```
.left[.footnote[**Fonte**: O Autor.]] 
]


.pull-right-3[
.center[**Implementa√ß√£o**]

**1** - Dividir o conjunto de dados em duas partes:
**treinamento** e **valida√ß√£o**.

  - Comumente: 70%/30% ou 80%/20% (treino/valida√ß√£o)

**2** - Usar uma parte para treinar o modelo (70% ou 80%), e a outra para validar (30% ou 20%).

**3** - Calcular o desempenho no conjunto de valida√ß√£o.
]

--
<br>

.pull.bottom[
.pull-left-3[
.shadow[
<br>.center[**Ponto Fraco**]

- **Alta vari√¢ncia**: 

  - A estimativa √© muito dependente da divis√£o (ou observa√ß√µes) que s√£o alocadas em cada conjunto.

  - Portanto, n√£o √© considerada a abordagem mais adequada para estimar o erro de generaliza√ß√£o.

]
]
]

<!--Slide XX -->
---
# .font80[M√©todos de Reamostragem: k-fold Cross-Validation]

.pull-left-3[
```{r, echo=FALSE, out.width="90%"}
knitr::include_graphics("gif/kCV10.gif")
```
.left[.footnote[**Fonte**: O Autor.]] 

**Repeated k-fold cross validation**: Simplesmente repete-se o processo (1 a 4) por $m$ vezes.
]


.pull-right-3[
.scroll-box-20[

.center[**Implementa√ß√£o**]

**1** - Dividir o conjunto de treinamento em k parti√ß√µes iguais e disjuntas; (5 ou 10)

  - Se k = 10 e existem 70 observa√ß√µes;
  - Ent√£o, cada parti√ß√£o teria 7 observa√ß√µes.

**2** - Usar k-1 parti√ß√µes para treinar o modelo e avaliar na parti√ß√£o que ficou de fora.

  - Conjunto de treinamento: 9 parti√ß√µes (63 obs.); e
  - Conjunto de valida√ß√£o: 1 parti√ß√£o (7 obs.).

**3** - Calcular o desempenho no conjunto de valida√ß√£o (ex.: RMSE)

**4** - Repetir as etapas 1, 2 e 3 por k vezes.

**5** - Calcular o desempenho m√©dio no conjunto de valida√ß√£o.
]
]


<!--Slide XX -->
---
# .font80[M√©todos de Reamostragem: Leave-One-Out Cross-Validation]

.pull-left-3[
```{r, echo=FALSE, out.width="90%"}
knitr::include_graphics("gif/LOOCV.gif")
```
.left[.footnote[**Fonte**: O Autor.]] 
]

.pull-right-3[
.scroll-box-20[

.center[**Implementa√ß√£o**]

**1** - Dividir o conjunto de treinamento em k = n parti√ß√µes;

- Em que: n = n√∫mero de observa√ß√µes (n = 70).

**2** - Usar k-1 parti√ß√µes para treinar o modelo e avaliar na parti√ß√£o que ficou de fora.

  - Conjunto de treinamento: 69 parti√ß√µes (69 obs.); e
  - Conjunto de valida√ß√£o: 1 parti√ß√£o (1 obs.).

**3** - Calcular o desempenho no conjunto de valida√ß√£o.

**4** - Repetir as etapas 1, 2 e 3 por k vezes.

**5** - Calcule o desempenho m√©dio no conjunto de valida√ß√£o.
]
]


<!-- Slide XX -->
<!-- --- -->
<!-- # Qual m√©todo de valida√ß√£o usar? -->

<!-- **N√£o existe uma regra de ouro!** -->

<!-- **Mas, existem algumas orienta√ß√µes gerais...** -->

<!-- - **k-fold Cross-Validation** -->
<!--   - Quando o conjunto de dado dispon√≠vel √© de tamanho m√©dio a grande; e -->
<!--   - Mais adequado para m√©todos com muitos hiperpar√¢metros de ajuste; -->
<!--   - Custo computacional √© maior do que Hold-out validation. -->

<!-- - **Leave-One-Out Cross-Validation** -->
<!--   - Quando o conjunto de dado dispon√≠vel √© de tamanho limitado; e -->
<!--   - Mais adequado para m√©todos com poucos hiperpar√¢metros de ajuste; -->
<!--   - Custo computacional √© maior do que k-fold Cross-Validation. -->


<!--Slide XX -->
---
name: md
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Medidas de Desempenho**]

.font100[**√â necess√°rio uma fun√ß√£o custo para medir o erro de predi√ß√£o...**]

<!--Slide XX -->
---
# Medidas de desempenho
<br>

- **Root Mean Square Error** (RMSE) / **Raiz do Erro Quadr√°tico M√©dio** (REQM)

\begin{equation}
{RMSE_{(k)}} =\sqrt{\frac{1}{n}\displaystyle\sum\limits_{i=1}^n\bigg(\hat{y_i}-y_i\bigg)^2}\\\\
\label{eq:RMSE}
\end{equation}


- **Relative Root Mean Square Error** (rRMSE)

\begin{equation}
{rRMSE_{(k)}} =\frac{100}{\bar{y}}\sqrt{\frac{1}{n}\displaystyle\sum\limits_{i=1}^n\bigg(\hat{y_i}-y_i\bigg)^2}\\\\
\label{eq:rRMSE}
\end{equation}


- **Mean Absolute Error** (MAE)

\begin{equation}
{MAE_{(k)}} =\frac{1}{n}\displaystyle\sum\limits_{i=1}^n|\hat{y_i}-y_i|\\\\
\label{eq:MAE}
\end{equation}


<!-- Slide XX -->
---
# Medidas de desempenho
<br>

- **Coefficient of Determination** (R¬≤)

\begin{equation}
{R_{(k)}^2} =\left(\frac{\displaystyle\sum\limits_{i=1}^n
\bigg(\hat{y_i}-\bar{\hat{y}}\bigg)
\bigg(y_i-\bar{y}\bigg)}
{\sqrt{\left [\displaystyle\sum\limits_{i=1}^n
\bigg(\hat{y_i}-\bar{\hat{y}}\bigg)^2 \right ]
\left [\displaystyle\sum\limits_{i=1}^n\bigg(y_i-\bar{y}\bigg)^2 \right]}}\right)^2\\\\
\label{eq:R2}
\end{equation}


- **Prediction Residual Error Sum of Squares** (PRESS)

\begin{equation}
PRESS = \displaystyle\sum\limits_{i=1}^n\bigg(y_i-\hat{y}_{i,-i}\bigg)^2 %\displaystyle\sum\limits_{i=1}^n\bigg(\frac{y_i-\hat{y}_{i}}{1-h_{ii}}\bigg)^2
\label{eq:PRESS}
\end{equation}

A estat√≠stica $PRESS$ √© baseada na abordagem **Leave-One-Out Cross Validation** (LOOCV).

Os erros de predi√ß√£o para as **amostras de valida√ß√£o** s√£o elevados ao quadrado e somados para formar a estat√≠stica PRESS.

< PRESS $\rightarrow$ melhor modelo


<!-- Slide XX -->
---
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Parte 2** <br> .green[Aprendizado de m√°quina <br> com linguagem R]]


<!-- Slide XX -->
---
name: bctv
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[**Bibliotecas no Cran Task View**]
<br>

.pull-left-2[
Fornecer uma orienta√ß√£o sobre os pacotes dispon√≠veis no reposit√≥rio CRAN que s√£o relevantes para tarefas relacionadas a um determinado t√≥pico.
]

<!-- Slide XX -->
---
class: middle
# Bibliotecas no Cran Task View

.pull-left[

Alguns pacotes publicados no Cran Task View: Machine Learning & Statistical learning

```{r, echo=FALSE, out.width='85%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/ML-FR.png')
```
]

.pull-right[
<BR> <BR> <BR> <BR> <BR>
Veja outros pacotes dispon√≠veis em Task View:

[Machine Learning & Statistical learning](https://cran.r-project.org/)

<BR> <BR>
Web scraping feito em 21/07/2018:

At√© julho de 2018 existiam 102 pacotes sobre AM
publicados no CRAN Task View.
]

.left[.footnote[Fonte: O Autor.]]


<!-- Slide XX -->
---
name: caret
class: inverse, left
background-image: url(fig/white.jpg)
background-size: cover

.font300[CARET]
	
.font200[(.red[C]lassication .red[A]nd .red[Re]gression .red[T]raining)]
	
`r Citep(myBib, c("kuhn2013applied", "R-caret"))`.
		
.font120["Constitui um conjunto de fun√ß√µes que tentam simplificar <br> o processo de constru√ß√£o de modelos preditivos."]

<br> <br> <br>

Web page: [CARET Package](https://topepo.github.io/caret/index.html)

<br> <br>

.left[.footnote[Imagem de <a href="https://pixabay.com/pt/users/pen_ash-5526837/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5358904">pen_ash</a> por <a href="https://pixabay.com/pt/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5358904">Pixabay</a>]]


<!-- Slide XX -->
---
# Pacote CARET: Ferramentas

```{r, echo=FALSE, out.width='50%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/CARET.png')
```


<!-- Slide XX -->
---
name: fluxo
background-image: url(fig/white.jpg)
background-size: cover

# .font80[Fluxograma: aprendizado de MAM usando CARET]

```{r, echo=FALSE, out.width='90%', fig.align='center', fig.cap=''}
knitr::include_graphics('fig/FM.png')
```
.left[.footnote[Fonte: `r Citet(myBib, "souza2020Tese")`.]]


<!-- Slide XX -->
---
name: exR
class: inverse, left
background-image: url(fig/white.jpg)
background-size: cover

.font200[Modelagem no R: uma r√°pida intui√ß√£o]
<br><br>

.font150[Acesse o c√≥digo R:]

Link: [01-wkNN](https://deivisonsouza.github.io/ML-Mensuracao-Florestal/R-scripts/01-wkNN.R)

.font100[(.green[Weighted *k*-Nearest Neighbors])]

.pull-left-2[
.font100[Uma varia√ß√£o do *k*-NN que usa fun√ß√µes kernel para ponderar os vizinhos mais pr√≥ximos de uma determinada observa√ß√£o...]

<br>

.font150[Acesse os dados:]

Link: [Tectona-grandis](https://deivisonsouza.github.io/ML-Mensuracao-Florestal/R-scripts/Tectona.csv)
]


<!-- Slide XX -->
---
name: shiny
class: inverse, top
background-image: url(fig/white.jpg)
background-size: cover

Como disponibilizar os modelos de aprendizado de m√°quina?

.pull-left[
```{r, echo=FALSE, out.width='20%', fig.align='center', fig.cap=''}
knitr::include_graphics('fig/sh.png')
```

.thick[.black[Biblioteca Shiny]]

.black[Biblioteca que facilita a cria√ß√£o de aplicativos da Web interativos usando diretamente a Linguagem R.]

.thick[.black[Shinyapps.io:]]

.black[Servidor gratuito para hospedar os aplicativos Shiny.]
<BR>

.thick[.black[Acesse aplica√ß√µes Web para predi√ß√£o de biomassa e volume: (Souza, 2020)]]

.font80[
[1-Shiny-MLMBio-Biomassa](https://deivisonsouza.shinyapps.io/MLBiomass/)

[2-Shiny-MLMVol-Volume](https://deivisonsouza.shinyapps.io/MLVolume/)
]
]

.column-right[
.thick[.black[Acesse a base para uso na aplica√ß√£o MLMBio:]] [Biomass-data](https://deivisonsouza.github.io/IA-Potencial-IF/R-scripts/data.csv)]

]


<!-- Slide XX -->
---
class: inverse, middle, left
background-image: url(fig/white.jpg)
background-size: cover

.font250[**Aplica√ß√µes nas ci√™ncias <br> florestais**]


<!-- Slide XX -->
---
name: aplicacoes
# Aplica√ß√µes nas ci√™ncias florestais

```{r, echo=FALSE, out.width='57%', fig.align='center', fig.cap=''}
knitr::include_graphics('fig/MindMap.png')
```

.left[.footnote[Fonte: O Autor.]]

<!-- Slide XX -->
---
name: AMIF
# .font80[AM na Mensura√ß√£o Florestal: estudos indicam potencial!]

```{r, echo=FALSE, out.width='80%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/ML-TEC.png')
```
.left[.footnote[Fonte: O Autor.]]

```{r}
Citep(myBib, c("diamantopoulou2010modelling", "nieto2012support", "sanquetta2013use", "diamantopoulou2005artificial", "ozccelik2010estimating", "schikowski2015estudo", "nunes2016artificial", "Corte2020", "montano2017artificial", "korhonen1997application", "maltamo2001most", "fehrmann2008comparison", "sanquetta2015comparison", "sanquetta2018volume", "souza2019",
               "james2013introduction"))
```

<!--Slide XX -->
---
# AM na Mensura√ß√£o Florestal: Volume

**Algumas pesquisa de AM na predi√ß√£o do volume...**

```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/TBV.png')
```
FP = Floresta Plantada; FN = Floresta Nativa; ANN = Artificial Neural Network. RL = Regress√£o Linear. S-H = Schumacher-Hall.


<!--Slide XX -->
---
# AM na Mensura√ß√£o Florestal: Altura

**Algumas pesquisa de AM na predi√ß√£o da altura...**

```{r, echo=FALSE, out.width='100%', fig.align='center', fig.cap='', dpi=600}
knitr::include_graphics('fig/TBA.png')
```
FP = Floresta Plantada; FN = Floresta Nativa; ANN = Artificial Neural Network. RL = Regress√£o Linear. S-H = Schumacher-Hall.


<!--Slide XX -->
---
name: cf
# Considera√ß√µes finais

.center[.font150[**Percep√ß√µes sobre as pesquisas...**]]
<br>

**Sob a √≥tica preditivista...**

.blockquote[
.center[**Aprendizado de M√°quina x M√©todos Tradicionais**]

<br>**1 - Desempenho preditivo**

√â fato que MAM t√™m mostrado competitividade, em termos de desempenho preditivo, frente aos m√©todos tradicionais.


<br>**2 - Superioridade**

a) Existem relatos de maior acur√°cia para MAM (ex.: RNA);

b) No entanto, isso nem sempre acontece e muitas vezes os **ganhos de acur√°cia n√£o parecem ser expressivos**; e

c) Nestes casos (item b), invocar o **princ√≠pio da parcim√¥nia** (escolher o modelo mais simples) parece ser mais plaus√≠vel.
]

<!--Slide XX -->
---
# Considera√ß√µes finais

.center[.font150[**Percep√ß√µes sobre as pesquisas...**]]
<br>

**Sob a √≥tica preditivista...**

.blockquote[
.center[**Aprendizado de M√°quina x M√©todos Tradicionais**]

<br>**3 - Covari√°veis tradicionais** 

<br>a) Algumas pesquisas consideram **apenas o uso de covari√°veis tradicionais** para ajustar MAM.


<br>b) Neste casos (item a), na maioria das vezes, os MAM **n√£o apresentam acur√°cia superior** em rela√ß√£o aos modelos cl√°ssicos (ex.: Schumacher-Hall).


<br>c) A **adi√ß√£o de novas covari√°veis** (qualitativas e quantitativas) parece contribuir para o aumento da acur√°cia. Neste ponto, √© poss√≠vel que MAM 
de modo mais expressivo quando usados MAM...
]

<!--Slide XX -->
---
# Considera√ß√µes finais

.center[.font150[**Relex√µes para pesquisas futuras...**]]

.blockquote[
**1 - Novas preditoras para aumento da acur√°cia**

- Refletir a possibilidade de inclus√£o de novas preditoras;

- Ponderar **diferentes abordagens** de modelagem e **refletir novas vari√°veis preditoras**, parece ser o caminho a
seguir na buscar por modelos biom√©tricos mais acurados.
]


---
# Refer√™ncias
<br>

```{r refs1, echo=FALSE, results="asis"}
PrintBibliography(myBib, start = 1, end = 5)
```

---
# Refer√™ncias
<br>

```{r refs2, echo=FALSE, results="asis"}
PrintBibliography(myBib, start = 6, end = 10)
```

---
# Refer√™ncias
<br>

```{r refs3, echo=FALSE, results="asis"}
PrintBibliography(myBib, start = 11, end = 15)
```
---
# Refer√™ncias
<br>

```{r refs4, echo=FALSE, results="asis"}
PrintBibliography(myBib, start = 16, end = 20)
```

---
# Refer√™ncias
<br>

```{r refs5, echo=FALSE, results="asis"}
PrintBibliography(myBib, start = 21, end = 25)
```
---
# Refer√™ncias
<br>

```{r refs6, echo=FALSE, results="asis"}
PrintBibliography(myBib, start = 26, end = 29)
```

---
class: inverse, top
background-image: url(fig/white.jpg)
background-size: cover

.pull-left[
.font300[Obrigado!]
 <br> <br> <br>

**Email**: <a href="mailto:deivisonvs@ufpa.br">deivisonvs@ufpa.br</a>

**Github**: <a href="https://github.com/DeivisonSouza">@DeivisonSouza</a>

<br>

.shadow[
Os slides, c√≥digos e demais arquivos desta apresenta√ß√£o est√£o dispon√≠veis no reposit√≥rio GitHub: [ML-Mensuracao-Florestal](https://github.com/DeivisonSouza/ML-Mensuracao-Florestal).
]
]

<!-- # Modelagem preditiva: linguagens (softwares) e frameworks -->

<!-- ```{r, engine='tikz', cache=TRUE, echo=FALSE, out.width='50%', fig.ext = 'png', bg = "transparent"} -->
<!-- \usetikzlibrary{mindmap} -->
<!-- \begin{tikzpicture} -->
<!-- 		[mindmap, -->
<!-- 		every node/.style={concept, execute at begin node=\hskip0pt, font=\bfseries}, -->
<!-- 		root concept/.append style={concept color=black, fill=white, line width=1ex, text=black, font=\huge\bfseries}, -->
<!-- 		method a/.style={concept color=red, line width=1ex, text=white}, -->
<!-- 		method b/.style={concept color=orange, line width=1ex, text=white}, -->
<!-- 		method c/.style={concept color=brown, line width=1ex, text=white}, -->
<!-- 		methods a/.style={concept color=red!50, line width=1ex, text=black}, -->
<!-- 		methods b/.style={concept color=orange!50, line width=1ex, text=black}, -->
<!-- 		methods c/.style={concept color=brown!50, line width=1ex, text=black}, -->
<!-- 		grow cyclic, -->
<!-- 		level 1/.append style={level distance=4.5cm, sibling angle=60}, -->
<!-- 		level 2/.append style={level distance=3cm, sibling angle=45}] -->
<!-- 		\node [root concept] {Liguagens/ \\ Software} % root -->
<!-- 		child [missing] {} -->
<!-- 		child [missing] {} -->
<!-- 		child [missing] {} -->
<!-- 		child [method a] { node {Python} -->
<!-- 			child [methods a] { node {A1} } -->
<!-- 			child [methods a] { node {A2} } -->
<!-- 			child [methods a] { node {A3} } -->
<!-- 			child [methods a] { node {A4} } -->
<!-- 			child [methods a] { node {A5} } -->
<!-- 			child [methods a] { node {A6} } -->
<!-- 			child [methods a] { node {A7} } } -->
<!-- 		child [missing] {} -->
<!-- 		child [method b] { node {R} -->
<!-- 			child [methods b] { node {B1} } -->
<!-- 			child [methods b] { node {B2} } -->
<!-- 			child [methods b] { node {B3} } -->
<!-- 			child [methods b] { node {B4} } -->
<!-- 			child [methods b] { node {B5} } -->
<!-- 			child [methods b] { node {B6} } -->
<!-- 			child [methods b] { node {B7} } } -->
<!-- 		child [missing] {} -->
<!-- 		child [method c] { node {Weka} -->
<!-- 			child [methods c] { node {C1} } -->
<!-- 			child [methods c] { node {C2} } -->
<!-- 			child [methods c] { node {C3} } -->
<!-- 			child [methods c] { node {C4} } -->
<!-- 			child [methods c] { node {C5} } -->
<!-- 			child [methods c] { node {C6} } -->
<!-- 			child [methods c] { node {C7} } }; -->
<!-- 		\end{tikzpicture} -->
<!-- ``` -->





